ğŸ—ï¸ System Design (Day 4)
Latency, Throughput & Tail Latency (P95, P99)
1ï¸âƒ£ Latency
ğŸ”¹ Definition

Time taken to process a single request end-to-end.

Measured in ms or seconds

Low latency = fast response

ğŸ”¹ Examples
Scenario	Latency
Simple API request	50ms
Database query	100ms
Image processing	500ms
ğŸ”¹ Interview Note

Latency is per-request performance, not overall system capacity.

2ï¸âƒ£ Throughput
ğŸ”¹ Definition

Number of requests processed per unit time.

Measured in req/sec or transactions/sec

High throughput = handles more traffic

ğŸ”¹ Examples
Scenario	Throughput
Single-threaded API	100 req/sec
Horizontally scaled service	10,000 req/sec
ğŸ”¹ Relation

Low latency â‰  high throughput
High throughput â‰  low latency

You need both for a performant system.

3ï¸âƒ£ Tail Latency â€” P95, P99
ğŸ”¹ Definition

The slowest percentile of requests.

P95 â†’ 95% of requests are faster than this time

P99 â†’ 99% of requests are faster than this time

ğŸ”¹ Why Important?

Average latency is misleading.

Example:

1000 requests â†’ 950 requests < 50ms, 50 requests = 500ms
Average = 72ms â†’ seems fine
Tail latency (P99) = 500ms â†’ 1% users experience lag


Users care about slowest experiences, not average

ğŸ”¹ Common Targets
Metric	Goal
P50	median response time
P95	â€œmost usersâ€ experience fast service
P99	â€œ99% of usersâ€ good experience
ğŸ”¹ Visualization
Latency (ms)
|
|                   x P99
|          x P95
|     x
| x P50
|____________________ Time â†’ requests


X-axis â†’ requests sorted by response time

Y-axis â†’ latency

P95, P99 are percentile markers

4ï¸âƒ£ How to Reduce Tail Latency

Parallelism

Run tasks concurrently (async calls)

Timeouts & Retries

Fail fast + retry secondary service

Caching

Reduce DB or external service calls

Load Balancing

Spread traffic evenly

Queueing & Rate Limiting

Avoid spikes causing tail latency

5ï¸âƒ£ Latency vs Throughput vs Tail Latency Table
Metric	Definition	Key Insight
Latency	Time per request	Focus on speed
Throughput	Requests/sec	Focus on capacity
Tail Latency (P95/P99)	Slowest percentile	Focus on user experience
ğŸ”¹ Interview Tip

FAANG systems care about tail latency, not just averages.
Design questions often test: â€œHow do you ensure 99% users get fast responses under high load?â€

6ï¸âƒ£ Example Question

Q: Design a video streaming API. How do you measure latency?
A:

Measure end-to-end response time for each request â†’ Latency

Track requests/sec â†’ Throughput

Track P95 / P99 latency â†’ Tail latency (e.g., slow users)

Optimize with caching + CDN + async streaming